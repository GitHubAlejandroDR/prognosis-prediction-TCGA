# -*- coding: utf-8 -*-
"""train_LGBM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15YlbyCLBLUPwB5PnyWPugKTm8nn_babE
"""

import numpy as np
import pandas as pd
from time import gmtime, strftime
import gc

from sklearn.model_selection import (train_test_split, GridSearchCV, StratifiedKFold)
from sklearn.preprocessing import LabelEncoder
import lightgbm as lgb
from tqdm import tqdm
from sklearn.metrics import (roc_curve, auc, accuracy_score, confusion_matrix, roc_auc_score, f1_score)

data_path_df = '/content/eIntegration_df.csv'
#data_path_df_Race = '/content/eIntegration_df_Race.csv'

# Load data
data = pd.read_csv(data_path_df)
#data = pd.read_csv(data_path_df_race)

# Set index
data = data.set_index('Unnamed: 0')
data.index.name = 'sample_id'

# Drop RACE column
data = data.drop(['RACE'], axis=1)

data['OS_STATUS'] = np.where(data['OS_STATUS'] == "X0", 0, 1)

def training_lgbm(grid_params, data):

    X = data.drop(columns = ['OS_STATUS'])
    y = data.iloc[:,data.columns == "OS_STATUS"]
    skf = StratifiedKFold(n_splits=5, random_state = 3000, shuffle = True)
    skf.get_n_splits(X, y)

    initial_params =  {
        'application': 'binary',
        'boosting': 'gbdt',
        'num_iterations': 100,
        'learning_rate': 0.05,
        'num_leaves': 62,
        'device': 'cpu',
        'max_depth': -1,
        'max_bin': 510,
        'lambda_l1': 5,
        'lambda_l2': 10,
        'metric' : 'binary_error',
        'subsample_for_bin': 200,
        'subsample': 1,
        'colsample_bytree': 0.8,
        'min_split_gain': 0.5,
        'min_child_weight': 1,
        'min_child_samples': 5
        }

    df_score = pd.DataFrame(columns = ['fold', 'ACC', 'AUC', 'F1'])
    list_dfs = list()
    test_samples = list()

    for i, (train_index, test_index) in enumerate(skf.split(X, y)):

        print(train_index.shape)
        print(test_index.shape)
        print(data.shape)

        df_train = data.iloc[train_index]
        X_train = df_train.drop(columns = ['OS_STATUS'])
        y_train = df_train.iloc[:,df_train.columns == "OS_STATUS"]

        df_test = data.iloc[test_index]
        X_test = df_test.drop(columns = ['OS_STATUS'])
        y_test = df_test.iloc[:,df_test.columns == "OS_STATUS"]

        params = {
        'application': 'binary',
        'boosting': 'gbdt',
        'num_iterations': 100,
        'learning_rate': 0.05,
        'num_leaves': 62,
        'device': 'cpu',
        'max_depth': -1,
        'max_bin': 510,
        'lambda_l1': 5,
        'lambda_l2': 10,
        'metric' : 'binary_error',
        'subsample_for_bin': 200,
        'subsample': 1,
        'colsample_bytree': 0.8,
        'min_split_gain': 0.5,
        'min_child_weight': 1,
        'min_child_samples': 5
        }

        # Initiate classifier to use
        mdl = lgb.LGBMClassifier(boosting_type= 'gbdt',
                objective = 'binary',
                n_jobs = 5,
                silent = True,
                max_depth = params['max_depth'],
                max_bin = params['max_bin'],
                subsample_for_bin = params['subsample_for_bin'],
                subsample = params['subsample'],
                min_split_gain = params['min_split_gain'],
                min_child_weight = params['min_child_weight'],
                min_child_samples = params['min_child_samples'])

        grid = GridSearchCV(mdl, gridParams, verbose=1, cv=2, n_jobs=-1, scoring = 'roc_auc')
        grid.fit(X_train, y_train)

        params['colsample_bytree'] = grid.best_params_['colsample_bytree']
        params['learning_rate'] = grid.best_params_['learning_rate']
        params['max_bin'] = grid.best_params_['max_bin']
        params['num_leaves'] = grid.best_params_['num_leaves']
        params['reg_alpha'] = grid.best_params_['reg_alpha']
        params['reg_lambda'] = grid.best_params_['reg_lambda']
        params['subsample'] = grid.best_params_['subsample']

        d_train = lgb.Dataset(X_train, label=y_train)

        model = lgb.train(params, train_set=d_train, num_boost_round=1000)

        p_test = model.predict(X_test)
        AUC_test = roc_auc_score(y_test, p_test)
        p_test = (p_test > 0.5).astype("int")
        ACC_test = accuracy_score(y_test, p_test)
        F1_test = f1_score(y_test, p_test)

        test_samples.append(df_test.index.values)

        params = initial_params

        # Define the new row to be added
        new_row_df_score = {'fold': str(i), 'AUC': AUC_test, 'ACC': ACC_test, 'F1': F1_test }
        # Use the loc method to add the new row to the DataFrame
        df_score.loc[len(df_score)] = new_row_df_score

        df_result_add = pd.DataFrame()
        df_result_add['predictions'] = p_test
        df_result_add['truth'] = y_test.values.reshape(1,-1).tolist()[0]
        df_result_add.index = df_test.index.values
        list_dfs.append(df_result_add)

    results = {'df_results': list_dfs, 'df_score': df_score, 'test_samples': test_samples}

    return results

# Hyperparameter tuning - Grid Search
gridParams = {
        'learning_rate': [0.005, 0.01],
        'n_estimators': [8,16,24,32],
        'num_leaves': [6,8,12,16,20],
        'boosting_type' : ['gbdt', 'dart'],
        'objective' : ['binary'],
        'max_bin':[255, 510],
        'random_state' : [300],
        'colsample_bytree' : [0.64, 0.65, 0.66],
        'subsample' : [0.7,0.75],
        'reg_alpha' : [1,1.2],
        'reg_lambda' : [1,1.2,1.4],
        }

# Results LGBM model
results_lgbm = training_lgbm(gridParams, data)

results_lgbm['df_score']

# Save evaluation results
results_lgbm['df_score'].to_csv('/content/df_score_eI.csv', index=False)

# Save predictions
results_lgbm['df_results'][0].to_csv('/content/df_results_eI_0.csv', index=True)
results_lgbm['df_results'][1].to_csv('/content/df_results_eI_1.csv', index=True)
results_lgbm['df_results'][2].to_csv('/content/df_results_eI_2.csv', index=True)
results_lgbm['df_results'][3].to_csv('/content/df_results_eI_3.csv', index=True)
results_lgbm['df_results'][4].to_csv('/content/df_results_eI_4.csv', index=True)